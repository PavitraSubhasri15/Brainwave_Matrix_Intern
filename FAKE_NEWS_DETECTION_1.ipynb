{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "X13hsxgoA43K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiJRK05lBDC-",
        "outputId": "d5d5e3ff-8fa2-4787-fa60-d2cd279ac147"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Label Data"
      ],
      "metadata": {
        "id": "7EpFJJgvBGha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "df_true = pd.read_csv(\"/content/True.csv\")\n",
        "\n",
        "df_fake[\"class\"] = 0\n",
        "df_true[\"class\"] = 1\n"
      ],
      "metadata": {
        "id": "zgE6r1q2BKLC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separate Manual Testing Data#"
      ],
      "metadata": {
        "id": "3SOb8vXfBQGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake_manual_testing = df_fake.tail(10)\n",
        "df_true_manual_testing = df_true.tail(10)\n",
        "\n",
        "df_fake = df_fake.iloc[:-10]\n",
        "df_true = df_true.iloc[:-10]\n"
      ],
      "metadata": {
        "id": "Lyp0LUoABT5T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge and Shuffle Data"
      ],
      "metadata": {
        "id": "4DEeqHR8BWVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge = pd.concat([df_fake, df_true], axis=0)\n",
        "df_merge = df_merge.sample(frac=1).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "NY2V2z_fBZnC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing Function"
      ],
      "metadata": {
        "id": "lSnKtaH_Bexv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub(\"\\\\W\", \" \", text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "VEFeQUeQBhD8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing to Text Data"
      ],
      "metadata": {
        "id": "1lrVwBpSBnFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge[\"text\"] = df_merge[\"text\"].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "f_vtLKOaBsUj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Data into Training and Testing Sets"
      ],
      "metadata": {
        "id": "uRFVfTxzB3G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_merge[\"text\"]\n",
        "y = df_merge[\"class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "ybzMJCmhBvP0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert Text Data to TF-IDF Features"
      ],
      "metadata": {
        "id": "pFgj_I_iB-dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "yZJbbewwBvTK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Logistic Regression with Grid Search"
      ],
      "metadata": {
        "id": "UqnPjt6QCII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\"C\": [0.01, 0.1, 1, 10, 100]}\n",
        "lr = LogisticRegression(max_iter=2000)\n",
        "\n",
        "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring=\"accuracy\")\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_lr = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "V6G1AunXCGRc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the Model"
      ],
      "metadata": {
        "id": "Y2F3mKTzCYt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = best_lr.predict(X_test_tfidf)\n",
        "\n",
        "print(f\"Best Logistic Regression Model: {grid_search.best_params_}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, pred_lr):.4f}\")\n",
        "print(classification_report(y_test, pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI23FXElCGrh",
        "outputId": "0d655f95-7749-4bde-b63c-9abdc2a388c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Model: {'C': 100}\n",
            "Accuracy: 0.9912\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      5868\n",
            "           1       0.99      0.99      0.99      5352\n",
            "\n",
            "    accuracy                           0.99     11220\n",
            "   macro avg       0.99      0.99      0.99     11220\n",
            "weighted avg       0.99      0.99      0.99     11220\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting test data"
      ],
      "metadata": {
        "id": "ekQO9SPGCo5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(best_lr, \"logistic_regression_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "\n",
        "best_lr = joblib.load(\"logistic_regression_model.pkl\")\n",
        "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "\n",
        "def predict_news(article):\n",
        "    article_tfidf = vectorizer.transform([article])\n",
        "    prediction = best_lr.predict(article_tfidf)\n",
        "    return \"Fake News\" if prediction[0] == 0 else \"Real News\"\n",
        "\n",
        "sample_fake_articles = df_fake_manual_testing[\"text\"].tolist()\n",
        "sample_true_articles = df_true_manual_testing[\"text\"].tolist()\n",
        "\n",
        "test_articles = sample_fake_articles + sample_true_articles\n",
        "ground_truth_labels = [\"Fake News\"] * len(sample_fake_articles) + [\"Real News\"] * len(sample_true_articles)\n",
        "\n",
        "for i, (article, actual_label) in enumerate(zip(test_articles, ground_truth_labels), 1):\n",
        "    predicted_label = predict_news(article)\n",
        "    print(f\"Article {i}: Predicted: {predicted_label} | Actual: {actual_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu8Sy8t-Dj6S",
        "outputId": "d767873b-36b0-4583-b4e8-301812adbf10"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 1: Predicted: Fake News | Actual: Fake News\n",
            "Article 2: Predicted: Fake News | Actual: Fake News\n",
            "Article 3: Predicted: Fake News | Actual: Fake News\n",
            "Article 4: Predicted: Fake News | Actual: Fake News\n",
            "Article 5: Predicted: Fake News | Actual: Fake News\n",
            "Article 6: Predicted: Fake News | Actual: Fake News\n",
            "Article 7: Predicted: Fake News | Actual: Fake News\n",
            "Article 8: Predicted: Fake News | Actual: Fake News\n",
            "Article 9: Predicted: Fake News | Actual: Fake News\n",
            "Article 10: Predicted: Fake News | Actual: Fake News\n",
            "Article 11: Predicted: Real News | Actual: Real News\n",
            "Article 12: Predicted: Real News | Actual: Real News\n",
            "Article 13: Predicted: Real News | Actual: Real News\n",
            "Article 14: Predicted: Real News | Actual: Real News\n",
            "Article 15: Predicted: Real News | Actual: Real News\n",
            "Article 16: Predicted: Real News | Actual: Real News\n",
            "Article 17: Predicted: Real News | Actual: Real News\n",
            "Article 18: Predicted: Real News | Actual: Real News\n",
            "Article 19: Predicted: Real News | Actual: Real News\n",
            "Article 20: Predicted: Real News | Actual: Real News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting general articles"
      ],
      "metadata": {
        "id": "AWSXaDJfD1gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "art=[\"Trump Declares War on Mainstream Media\",\"Breaking reports suggest that President Joe Biden has decided to step down from office due to severe health complications. Sources claim that Vice President Kamala Harris will take over immediately, although no official announcement has been made yet.\",\"WASHINGTON (Reuters) - Lawmakers are in tense negotiations as Congress debates whether to raise the U.S. debt ceiling. With the deadline approaching, Democrats and Republicans remain divided on key fiscal policies.\"]\n",
        "for i, article in enumerate(art, 1):\n",
        "    print(f\"Article {i}: {predict_news(article)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV_X7NZGD6VK",
        "outputId": "6f3ddf52-e178-43bf-c766-3ab0e70564ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 1: Fake News\n",
            "Article 2: Fake News\n",
            "Article 3: Real News\n"
          ]
        }
      ]
    }
  ]
}